{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02283ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import scrapy as sc\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import time\n",
    "import re\n",
    "\n",
    "from clickhouse_driver import Client\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "#Перманентно поменял настройки вывода графиков\n",
    "from matplotlib import pylab\n",
    "from pylab import *\n",
    "pylab.rcParams['figure.figsize'] = (18.0, 6.0)\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "#Скрыл вывод предупреждений.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #чтобы вернуть: (action='once')\n",
    "\n",
    "# Глобально снял ограничение на кол-во отображаемых результатов для каждой ячейки ввода кода.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Включил возможность форматировать стили текста с помощью метода printmd()\n",
    "from IPython.display import Markdown, display, HTML\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "# Снял ограничение на вывод кол-ва столбцов и ширины колонки.\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# Установил формат вывода в таблице на 2 знака после запятой.\n",
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "    \n",
    "# Добавил функцию вывода таблиц в одну строку, для экономии пространства и улучшения восприятия информации.\n",
    "def display_side_by_side(dfs:list, captions:list):\n",
    "    output = \"\"\n",
    "    combined = dict(zip(captions, dfs))\n",
    "    for caption, df in combined.items():\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += \"\\xa0\\xa0\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6616b0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Настроил логер\n",
    "logger.add('logs/logs.log', format=\"{time} {level} {message}\", filter=\"my_module\", level=\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e540c9ee",
   "metadata": {},
   "source": [
    "### Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19578f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сделал запрос на скачивание xml-файла из s3 бакета со списком всех zip архивов.\n",
    "test_req = requests.get('https://s3.amazonaws.com/tripdata')\n",
    "\n",
    "#Записал файл в pandas датафрейм.\n",
    "tt = pd.read_xml(test_req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59e011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201306-citibike-tripdata.zip</td>\n",
       "      <td>2018-04-30T13:18:55.000Z</td>\n",
       "      <td>\"b520a12de58eea58a3586f89bfcfbd9d-2\"</td>\n",
       "      <td>16,785,103.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201307-201402-citibike-tripdata.zip</td>\n",
       "      <td>2017-01-18T22:23:25.000Z</td>\n",
       "      <td>\"7b3b260b2ab2e5349320121d04bd821c-22\"</td>\n",
       "      <td>178,262,576.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201307-citibike-tripdata.zip</td>\n",
       "      <td>2017-01-18T22:23:27.000Z</td>\n",
       "      <td>\"dd3e6fd5f91715b31eae72868086c08c-4\"</td>\n",
       "      <td>27,074,629.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Key              LastModified                                   ETag            Size\n",
       "0  201306-citibike-tripdata.zip         2018-04-30T13:18:55.000Z  \"b520a12de58eea58a3586f89bfcfbd9d-2\"  16,785,103.000 \n",
       "1  201307-201402-citibike-tripdata.zip  2017-01-18T22:23:25.000Z  \"7b3b260b2ab2e5349320121d04bd821c-22\" 178,262,576.000\n",
       "2  201307-citibike-tripdata.zip         2017-01-18T22:23:27.000Z  \"dd3e6fd5f91715b31eae72868086c08c-4\"  27,074,629.000 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Отсеял все поля, которые не содержат значения Key(название zip-файла)\n",
    "table_source = tt[tt['Key'] == tt['Key']].iloc[:, 3:-1].reset_index(drop=True)[:-1]\n",
    "table_source.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a62657b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201306-citibike-tripdata.zip</td>\n",
       "      <td>2018-04-30T13:18:55.000Z</td>\n",
       "      <td>\"b520a12de58eea58a3586f89bfcfbd9d-2\"</td>\n",
       "      <td>16,785,103.000</td>\n",
       "      <td>https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201307-201402-citibike-tripdata.zip</td>\n",
       "      <td>2017-01-18T22:23:25.000Z</td>\n",
       "      <td>\"7b3b260b2ab2e5349320121d04bd821c-22\"</td>\n",
       "      <td>178,262,576.000</td>\n",
       "      <td>https://s3.amazonaws.com/tripdata/201307-201402-citibike-tripdata.zip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201307-citibike-tripdata.zip</td>\n",
       "      <td>2017-01-18T22:23:27.000Z</td>\n",
       "      <td>\"dd3e6fd5f91715b31eae72868086c08c-4\"</td>\n",
       "      <td>27,074,629.000</td>\n",
       "      <td>https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Key  ...                                                                    url\n",
       "0  201306-citibike-tripdata.zip         ...  https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip       \n",
       "1  201307-201402-citibike-tripdata.zip  ...  https://s3.amazonaws.com/tripdata/201307-201402-citibike-tripdata.zip\n",
       "2  201307-citibike-tripdata.zip         ...  https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip       \n",
       "\n",
       "[3 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Создал колонку с url\n",
    "table_source['url'] =  table_source['Key'].apply(lambda x: 'https://s3.amazonaws.com/tripdata/' + str(x))\n",
    "table_source.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "177a6bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 23:52:28.771 | INFO     | __main__:<cell line: 1>:1 - Сравнение таблицы исходника с актуальной версией\n",
      "2022-09-14 23:52:28.775 | INFO     | __main__:<cell line: 5>:6 - Таблица загрузчика существует.\n",
      "2022-09-14 23:52:28.804 | INFO     | __main__:<cell line: 5>:18 - Изменений нет.\n"
     ]
    }
   ],
   "source": [
    "logger.info('Сравнение таблицы исходника с актуальной версией')\n",
    "#Файл etl_log.csv хранит актуальную историю последней выгрузки. \n",
    "\n",
    "#Если файл уже существует, то скрипт открывает его и удаляет колонку update\n",
    "if os.path.exists('etl_log.csv'):\n",
    "    logger.info('Таблица загрузчика существует.')\n",
    "    \n",
    "    table_actual = pd.read_csv('etl_log.csv',sep=\";\")\n",
    "    del table_actual['update'] #колонка update указывает следует ли загружать файл\n",
    "    \n",
    "    #Объединяются 2 таблицы для построчного сравнения. В результате создается колонка обноваленная колонка update\n",
    "    table_final=table_source.merge(table_actual,indicator=True,how='left')\n",
    "    table_final._merge=table_final._merge.eq('both')\n",
    "    table_final = table_final.rename(columns={'_merge':'update'})\n",
    "    table_final['update'] = ~table_final['update']\n",
    "\n",
    "    #Подсчитывается количество изменений и выводиться соответствующее сообщение.\n",
    "    changes = table_final[table_final['update'] != False]\n",
    "    \n",
    "    if len(changes) == 0:\n",
    "        logger.info('Изменений нет.')\n",
    "    else:\n",
    "        logger.info(len(changes) + 'изменений найдено.')\n",
    "#Если файл не существует, то создает его с указанными по умолчанию значениями.\n",
    "else:\n",
    "    table_source['downloaded'] = False #метка был ли скачан файл.\n",
    "    table_source['extracted'] = False #метка были ли разархивирован файл.\n",
    "    table_source['ch_uploaded'] = False #метка был ли файл загружен в БД clickhouse.\n",
    "    table_source['csv'] = 'No' #название csv файла при его существовании.\n",
    "    \n",
    "    table_source.to_csv('etl_log.csv',sep=\";\",index=False)\n",
    "    \n",
    "    logger.info('Файл таблицы создан.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e142e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>LastModified</th>\n",
       "      <th>ETag</th>\n",
       "      <th>Size</th>\n",
       "      <th>url</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>extracted</th>\n",
       "      <th>ch_uploaded</th>\n",
       "      <th>csv</th>\n",
       "      <th>update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201306-citibike-tripdata.zip</td>\n",
       "      <td>2018-04-30T13:18:55.000Z</td>\n",
       "      <td>\"b520a12de58eea58a3586f89bfcfbd9d-2\"</td>\n",
       "      <td>16,785,103.000</td>\n",
       "      <td>https://s3.amazonaws.com/tripdata/201306-citibike-tripdata.zip</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>201306-citibike-tripdata.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201307-201402-citibike-tripdata.zip</td>\n",
       "      <td>2017-01-18T22:23:25.000Z</td>\n",
       "      <td>\"7b3b260b2ab2e5349320121d04bd821c-22\"</td>\n",
       "      <td>178,262,576.000</td>\n",
       "      <td>https://s3.amazonaws.com/tripdata/201307-201402-citibike-tripdata.zip</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2013-07 - Citi Bike trip data.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201307-citibike-tripdata.zip</td>\n",
       "      <td>2017-01-18T22:23:27.000Z</td>\n",
       "      <td>\"dd3e6fd5f91715b31eae72868086c08c-4\"</td>\n",
       "      <td>27,074,629.000</td>\n",
       "      <td>https://s3.amazonaws.com/tripdata/201307-citibike-tripdata.zip</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2013-07 - Citi Bike trip data.csv</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Key              LastModified  ...                                csv  update\n",
       "0  201306-citibike-tripdata.zip         2018-04-30T13:18:55.000Z  ...  201306-citibike-tripdata.csv       False \n",
       "1  201307-201402-citibike-tripdata.zip  2017-01-18T22:23:25.000Z  ...  2013-07 - Citi Bike trip data.csv  False \n",
       "2  201307-citibike-tripdata.zip         2017-01-18T22:23:27.000Z  ...  2013-07 - Citi Bike trip data.csv  False \n",
       "\n",
       "[3 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e8d499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Методы сохранения файлов\n",
    "def get_file_file(url): #делаем запрос на сам файл\n",
    "    try:\n",
    "        r = requests.get(url, stream=True)\n",
    "        return r\n",
    "    except:\n",
    "        print('Нет коннекта при соединении с файлом по указанной ссылке.')\n",
    "        logger.info('Нет коннекта при соединении с файлом по указанной ссылке.')\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_file_name(url): #получаем имя файла\n",
    "    try:\n",
    "        name = url.split('/')[-1]  #потрошим ссылку через / и берём оттуда последние данные\n",
    "        return name\n",
    "    except:\n",
    "        return url\n",
    "\n",
    "def save_file(name, file_object): #сохраняет файл в корневой папке\n",
    "    try:\n",
    "        path = './files/'+name\n",
    "        with open(path, 'bw') as f:\n",
    "            for chunk in file_object.iter_content(None):\n",
    "                f.write(chunk)\n",
    "            print(str(name)+' загружен')\n",
    "            logger.info(str(name)+' загружен')\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3d698cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Директория сохранения файлов\n",
    "dir_path = r'./files/'\n",
    "\n",
    "# Список файлов в директории\n",
    "res = os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e881ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция извлекает csv-файл из архива в путь ./files/csv/, принимает атрибуты: имя файла, индекс.\n",
    "def zip_extractor(target_file, index):\n",
    "    endswith = '.csv'\n",
    "    try:\n",
    "        path = Path(target_file)\n",
    "        target_file_size = path.stat().st_size\n",
    "        \n",
    "        with zipfile.ZipFile(target_file) as z:\n",
    "            for file in z.namelist():\n",
    "                if file.endswith(endswith):\n",
    "                    if (target_file_size) > 0:\n",
    "                        logger.info(\"Извлекаемый из архива файл существует: \"+file)\n",
    "                    else:\n",
    "                        z.extract(file,'./files/csv/')\n",
    "                logger.info(file+\" файл разархивирован\")\n",
    "                if file[1] != \"_\":\n",
    "                    table_final.at[index, 'csv'] = file\n",
    "        table_final.at[index, 'extracted'] = True\n",
    "    except ValueError as ve:\n",
    "        logger.info(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Итератор проходит по созданной ранее таблице с актуальной версией инструкций экстракции. \n",
    "for index, row in table_final.iterrows():\n",
    "    file = row['url']\n",
    "    filename = file.split('/')[-1]\n",
    "    try:\n",
    "        path = Path(dir_path+filename)\n",
    "        target_file_size = path.stat().st_size\n",
    "    except:\n",
    "        logger.info(\"Файл скачивается: \"+file)\n",
    "        save_file(get_file_name(file), get_file_file(file))\n",
    "    else:\n",
    "        if (target_file_size) > 0:\n",
    "            logger.info(\"Файл существует: \"+filename)\n",
    "        else:\n",
    "            logger.info(\"Файл скачан не полностью, продолжается скачивание: \"+file)\n",
    "            save_file(get_file_name(file), get_file_file(file))\n",
    "            \n",
    "    table_final.at[index, 'downloaded'] = True\n",
    "    zip_extractor('.\\\\'+str(path),index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2911888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение изменений инструкций экстракции.\n",
    "table_final.to_csv('etl_log.csv',sep=\";\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b6357",
   "metadata": {},
   "source": [
    "### Transform Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa897c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Функция просеивает данные из одного csv файла, группирует их по условию и загружает в БД в три разные таблицы. Принимает атрибуты: имя файла, индекс.\n",
    "def load_trip(filename,index):\n",
    "    try:\n",
    "        #Читаем csv файл в Dataframe\n",
    "        df = pd.read_csv('./files/csv/'+filename)\n",
    "#         df.info()\n",
    "        \n",
    "        #Приводим колонки к одному виду\n",
    "        df.columns = df.columns.str.replace(' ', '')\n",
    "        df.columns = df.columns.str.lower()\n",
    "        try:\n",
    "            df['stop_date'] = pd.to_datetime(df['stoptime'])\n",
    "        except:\n",
    "            df = df.rename(columns={'ended_at':'stop_date','ride_id':'bikeid','':'tripduration','member_casual':'gender'})\n",
    "            df['stop_date'] = pd.to_datetime(df['stop_date'])\n",
    "            df['started_at'] = pd.to_datetime(df['started_at'])\n",
    "            df['tripduration'] = (df['stop_date'] - df['started_at']) / np.timedelta64(1, 's')\n",
    "            df = df.replace('member', 1).replace('casual', 2)\n",
    "            pass\n",
    "            \n",
    "        #Преобразуем тип данных для работы со временем.\n",
    "        df['stop_date'] = df['stop_date'].astype('datetime64[D]')\n",
    "    #     df.head(5)\n",
    " \n",
    "        #Группируем датафреймы по дням, следуя условиям задания.\n",
    "        trips_count_daily = df.groupby('stop_date')['bikeid'].count().to_frame().reset_index().rename(columns={'bikeid':'trips_count','stop_date':'date'})\n",
    "    #     trips_count_daily.head(10)\n",
    "        avg_duration_daily = df.groupby('stop_date')['tripduration'].mean().to_frame().reset_index().rename(columns={'tripduration':'avg_trip_dur','stop_date':'date'})\n",
    "    #     avg_duration_daily.head(10)\n",
    "        gender_df = df.groupby('stop_date')['bikeid'].count().to_frame()\n",
    "        \n",
    "\n",
    "        for sex in df['gender'].unique():\n",
    "            gender_df['gender_'+str(sex)] = df[df['gender'] == sex].groupby('stop_date')['gender'].count().to_frame()\n",
    "        gender_daily = gender_df.reset_index().rename(columns={'stop_date':'date'}) \n",
    "        del gender_daily['bikeid']\n",
    "        for sex in df['gender'].unique():\n",
    "            gender_daily['gender_'+str(sex)] = gender_daily['gender_'+str(sex)].fillna(0).astype(int)  \n",
    "        if 'gender_0' not in gender_daily.columns:\n",
    "            gender_daily['gender_0'] = 0\n",
    "    #     gender_daily.head(5)\n",
    "\n",
    "        #Создаем коннект к Clickhouse. В clickhouse. Файлы DDL в папке проекта. Для таблиц использовались движки ReplacingMergeTree и AggregatingMergeTree\n",
    "        client = Client(host='localhost', settings={'use_numpy': True}).from_url('clickhouse://default:@localhost:19000/default') #логин пароль порт по умолчанию, дефолтная БД тоже по умолчанию\n",
    "    #     result = client.execute(\"SHOW TABLES\")\n",
    "    #     print(result)\n",
    "\n",
    "        client.execute('INSERT INTO `default`.gender_daily VALUES', gender_daily.to_dict('records'),types_check=True)\n",
    "        client.execute('OPTIMIZE TABLE `default`.gender_daily')\n",
    "    #     client.query_dataframe('SELECT * FROM gender_daily')\n",
    "\n",
    "        client.execute('INSERT INTO `default`.trips_count_daily VALUES', trips_count_daily.to_dict('records'),types_check=True)\n",
    "        client.execute('OPTIMIZE TABLE `default`.trips_count_daily')\n",
    "    #     client.query_dataframe('SELECT * FROM trips_count_daily')\n",
    "\n",
    "        client.execute('INSERT INTO `default`.avg_duration_daily VALUES', avg_duration_daily.to_dict('records'),types_check=True)\n",
    "        client.execute('OPTIMIZE TABLE `default`.avg_duration_daily')\n",
    "    # client.query_dataframe('SELECT * FROM avg_duration_daily')\n",
    "        table_final.at[index, 'ch_uploaded'] = True\n",
    "        logger.info('Файл успешно загружен в БД: ' + filename)\n",
    "    except ValueError as ve:\n",
    "        logger.info(ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Итератор выполняют функцию load_trip, тем самым обрабатывает и загружает подготовленные данные в БД.\n",
    "for index, row in table_final.iterrows():\n",
    "    uploaded = row['ch_uploaded']\n",
    "    if uploaded != True:\n",
    "        load_trip(row['csv'],index)\n",
    "    else:\n",
    "        logger.info('Датасет уже существует в БД: ' + row['csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd1a70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сохранение изменений инструкций экстракции.\n",
    "table_final.to_csv('etl_log.csv',sep=\";\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
